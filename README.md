# Waste Classification using Deep Learning

A deep learning project for waste classification using transfer learning with pre-trained CNN models (VGG19, ResNet50, and EfficientNetB0).

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [Dataset](#dataset)
- [Project Structure](#project-structure)
- [Models](#models)
- [Installation](#installation)
- [Usage](#usage)
- [Results](#results)
- [Features](#features)
- [Team](#team)
- [Contributing](#contributing)

## ğŸ¯ Overview

This project implements a waste classification system using deep learning techniques. The goal is to automatically classify waste images into 6 different categories: cardboard, glass, metal, paper, plastic, and trash. The project compares the performance of three popular pre-trained CNN architectures through transfer learning.

## ğŸ“Š Dataset

The project uses the TrashNet dataset with the following categories:
- **Cardboard** - Cardboard waste items
- **Glass** - Glass bottles and containers
- **Metal** - Metal cans and containers
- **Paper** - Paper waste items
- **Plastic** - Plastic bottles and containers
- **Trash** - General trash items

### Dataset Split:
- **Training**: 80% of the data
- **Validation**: ~13% of the data
- **Test**: ~7% of the data

All images are resized to 224x224 pixels for model input.

## ğŸ“ Project Structure

```
tubes_fix/
â”‚
â”œâ”€â”€ test.ipynb                          # Main Jupyter notebook
â”œâ”€â”€ README.md                           # Project documentation
â”‚
â”œâ”€â”€ DatasetTrashnet/
â”‚   â””â”€â”€ dataset-resized/               # Original dataset
â”‚       â”œâ”€â”€ cardboard/
â”‚       â”œâ”€â”€ glass/
â”‚       â”œâ”€â”€ metal/
â”‚       â”œâ”€â”€ paper/
â”‚       â”œâ”€â”€ plastic/
â”‚       â””â”€â”€ trash/
â”‚
â”œâ”€â”€ data_split/                        # Processed dataset splits
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ validation/
â”‚   â””â”€â”€ test/
â”‚
â”œâ”€â”€ models/                            # Saved model files
â”‚   â”œâ”€â”€ VGG19_fine_tuned_final.keras
â”‚   â”œâ”€â”€ ResNet50_fine_tuned_final.keras
â”‚   â”œâ”€â”€ EfficientNetB0_fine_tuned_final.keras
â”‚   â””â”€â”€ efficientnetb0_notop.h5
â”‚
â””â”€â”€ logs/                              # TensorBoard logs
    â””â”€â”€ fit/
        â”œâ”€â”€ VGG19_initial/
        â”œâ”€â”€ VGG19_finetune/
        â”œâ”€â”€ ResNet50_initial/
        â”œâ”€â”€ ResNet50_finetune/
        â”œâ”€â”€ EfficientNetB0_initial/
        â””â”€â”€ EfficientNetB0_finetune/
```

## ğŸ¤– Models

This project implements and compares three state-of-the-art CNN architectures:

### 1. VGG19
- **Architecture**: 19-layer Visual Geometry Group network
- **Pre-trained on**: ImageNet
- **Fine-tuning**: Last 4 layers unfrozen

### 2. ResNet50
- **Architecture**: 50-layer Residual Network
- **Pre-trained on**: ImageNet
- **Fine-tuning**: Last 22 layers unfrozen

### 3. EfficientNetB0
- **Architecture**: Efficient Neural Network B0
- **Pre-trained weights**: Custom weights (efficientnetb0_notop.h5)
- **Fine-tuning**: Last 20 layers unfrozen

### Training Strategy

Each model follows a two-phase training approach:

1. **Initial Training Phase**:
   - Frozen base model layers
   - Learning rate: 1e-3
   - Epochs: Up to 80 (with early stopping)

2. **Fine-tuning Phase**:
   - Unfrozen top layers
   - Learning rate: 1e-5
   - Epochs: Up to 20 (with early stopping)

## ğŸš€ Installation

### Prerequisites
- Python 3.8+
- CUDA-capable GPU (recommended)

### Required Packages

```bash
pip install tensorflow
pip install numpy pandas matplotlib seaborn
pip install opencv-python pillow
pip install scikit-learn
pip install pathlib
```

### Alternative: Using conda

```bash
conda install tensorflow-gpu
conda install numpy pandas matplotlib seaborn
conda install opencv pillow
conda install scikit-learn
```

## ğŸ’» Usage

1. **Clone the repository**:
   ```bash
   git clone <your-repository-url>
   cd tubes_fix
   ```

2. **Prepare the dataset**:
   - Place your dataset in `DatasetTrashnet/dataset-resized/` folder
   - Ensure each category has its own subfolder

3. **Run the notebook**:
   ```bash
   jupyter notebook test.ipynb
   ```

4. **Execute cells sequentially**:
   - **EDA Section**: Analyze dataset distribution and image properties
   - **Preprocessing**: Split data and create data loaders
   - **Model Training**: Train each model (VGG19, ResNet50, EfficientNetB0)
   - **Evaluation**: Compare model performances

## ğŸ“ˆ Results

The project provides comprehensive evaluation metrics:

- **Test Accuracy**: Final accuracy on unseen test data
- **Classification Report**: Precision, recall, and F1-score for each class
- **Confusion Matrix**: Visual representation of classification performance
- **Training History**: Accuracy and loss curves during training

### Key Features of Results:
- Comparison table of all three models
- Visual performance comparison charts
- Detailed per-class performance metrics
- Training history visualization

## âœ¨ Features

### Data Analysis
- **Dataset Distribution**: Visual analysis of class balance
- **Image Properties**: Analysis of image dimensions, aspect ratios, and blur metrics
- **Sample Visualization**: Display sample images from each category

### Data Preprocessing
- **Automatic Data Splitting**: Stratified train/validation/test split
- **Data Augmentation**: Random flip, rotation, and zoom
- **Class Balancing**: Automatic class weight computation
- **Batch Processing**: Efficient data loading with TensorFlow datasets

### Model Training
- **Transfer Learning**: Leverages pre-trained ImageNet weights
- **Two-Phase Training**: Initial training + fine-tuning approach
- **Callbacks**: Model checkpointing, early stopping, and TensorBoard logging
- **Performance Monitoring**: Real-time training progress tracking

### Evaluation
- **Multiple Metrics**: Accuracy, precision, recall, F1-score
- **Visual Analysis**: Confusion matrices and performance charts
- **Model Comparison**: Side-by-side performance comparison

## ğŸ‘¥ Team

**Kelompok Bebas**

This project was developed by:

| Name | Student ID | Email | Role |
|------|------------|-------|------|
| Fairus Rajendra Wiranata | 101121050 | fairus344@gmail.com | Team Leader / Model Architecture |
| Ni Putu Merta Bhuana N | 105222008 | putumertabhuana@gmail.com | Data Preprocessing / EDA |
| Arshanda Geulis Nawajaputri | 105222045 | arshandagn06@gmail.com | Model Training / Optimization |
| Yan Stephen Christian Immanuel | 105222010 | yan.stephen49@gmail.com | Evaluation / Documentation |

### Contributions:
- **Fairus Rajendra Wiranata**: Designed model architectures, implemented transfer learning approach
- **Ni Putu Merta Bhuana N**: Performed exploratory data analysis, data preprocessing and augmentation  
- **Arshanda Geulis Nawajaputri**: Handled model training, hyperparameter tuning, and performance optimization
- **Yan Stephen Christian Immanuel**: Conducted model evaluation, created visualizations, and wrote documentation

## ğŸ¤ Contributing

1. Fork the project
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ Notes

- The project uses TensorFlow/Keras for deep learning implementation
- All models are saved in `.keras` format for compatibility
- TensorBoard logs are generated for training visualization
- The notebook includes error handling for missing files and directories

## ğŸ† Performance Tips

- Use GPU acceleration for faster training
- Monitor TensorBoard logs for training insights
- Adjust batch size based on available memory
- Consider data augmentation parameters based on your dataset

---

**Team**: Kelompok Bebas  
**Members**: Fairus Rajendra Wiranata, Ni Putu Merta Bhuana N, Arshanda Geulis Nawajaputri, Yan Stephen Christian Immanuel  
**Course**: Machine Learning  
**Institution**: Universitas Pertamina
**Date**: July 2025
